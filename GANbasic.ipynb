{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANbasic.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNX5+64gXHSP0A18zD4cL5W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heaven-hand/idshwk1/blob/main/GANbasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU7_5Z5E2jyj"
      },
      "source": [
        "Generative Adversarial Network\n",
        "Download Dataset\n",
        "下载 dataset，安装 python 的套件 gdown 来下载。可以保存到 google drive 上。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNhaImes1X1P"
      },
      "source": [
        "\"\"\" Uncomment these lines to mount your own gdrive. \"\"\"\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\"\"\" You can replace the workspace directory with your gdrive if you want. \"\"\"\n",
        "workspace_dir = '.'\n",
        "# workspace_dir = './drive/My Drive/Machine Learning/hw11 - GAN/colab_tmp'\n",
        "\n",
        "\"\"\" Download the dataset. \"\"\"\n",
        "!gdown --id 1IGrTr308mGAaCKotpkkm8wTKlWs9Jq-p --output \"{workspace_dir}/crypko_data.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg8m7mD42l-T"
      },
      "source": [
        "!unzip -q \"{workspace_dir}/MNIST_GAN_1000.zip\" -d \"{workspace_dir}/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5em8PdPq2p4d"
      },
      "source": [
        "Prepare Data\n",
        "定义 dataset，由于要使用 torchvision 这个套件来保存图片，因此需要将 cv2 读取进来的图片（BGR）转换为 torchvision 的格式（RGB）。\n",
        "\n",
        "定义 preprocess: 将 input 形状 resize 到 (64, 64)，并将其 value 由 0~1 线性转换到 -1~1。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q98XQ9jf2qzQ"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, fnames, transform):\n",
        "        self.transform = transform\n",
        "        self.fnames = fnames\n",
        "        self.num_samples = len(self.fnames)\n",
        "    def __getitem__(self,idx):\n",
        "        fname = self.fnames[idx]\n",
        "        img = cv2.imread(fname)\n",
        "        img = self.BGR2RGB(img) #because \"torchvision.utils.save_image\" use RGB\n",
        "        img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def BGR2RGB(self,img):\n",
        "        return cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "import glob\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def get_dataset(root):\n",
        "    fnames = glob.glob(os.path.join(root, '*'))\n",
        "    # resize the image to (64, 64)\n",
        "    # linearly map [0, 1] to [-1, 1]\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToPILImage(),\n",
        "         transforms.Resize((64, 64)),\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3) ] )\n",
        "    dataset = FaceDataset(fnames, transform)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLY20aMb2u6_"
      },
      "source": [
        "Some useful functions\n",
        "random seed 函数，以便 reproduce。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crXLFCKS2vmg"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    random.seed(seed)  # Python random module.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vdxQWnT2zBt"
      },
      "source": [
        "\n",
        "Model\n",
        "使用 DCGAN 作为 baseline mode。如图为DCGAN 架构。（图中的参数仅为参考）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHOApo622zht"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    input (N, in_dim)\n",
        "    output (N, 3, 64, 64)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        def dconv_bn_relu(in_dim, out_dim):\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_dim, out_dim, 5, 2,\n",
        "                                   padding=2, output_padding=1, bias=False),\n",
        "                nn.BatchNorm2d(out_dim),\n",
        "                nn.ReLU())\n",
        "        self.l1 = nn.Sequential(\n",
        "            nn.Linear(in_dim, dim * 8 * 4 * 4, bias=False),\n",
        "            nn.BatchNorm1d(dim * 8 * 4 * 4),\n",
        "            nn.ReLU())\n",
        "        self.l2_5 = nn.Sequential(\n",
        "            dconv_bn_relu(dim * 8, dim * 4),\n",
        "            dconv_bn_relu(dim * 4, dim * 2),\n",
        "            dconv_bn_relu(dim * 2, dim),\n",
        "            nn.ConvTranspose2d(dim, 3, 5, 2, padding=2, output_padding=1),\n",
        "            nn.Tanh())\n",
        "        self.apply(weights_init)\n",
        "    def forward(self, x):\n",
        "        y = self.l1(x)\n",
        "        y = y.view(y.size(0), -1, 4, 4)\n",
        "        y = self.l2_5(y)\n",
        "        return y\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    input (N, 3, 64, 64)\n",
        "    output (N, )\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, dim=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        def conv_bn_lrelu(in_dim, out_dim):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_dim, out_dim, 5, 2, 2),\n",
        "                nn.BatchNorm2d(out_dim),\n",
        "                nn.LeakyReLU(0.2))\n",
        "        self.ls = nn.Sequential(\n",
        "            nn.Conv2d(in_dim, dim, 5, 2, 2), nn.LeakyReLU(0.2),\n",
        "            conv_bn_lrelu(dim, dim * 2),\n",
        "            conv_bn_lrelu(dim * 2, dim * 4),\n",
        "            conv_bn_lrelu(dim * 4, dim * 8),\n",
        "            nn.Conv2d(dim * 8, 1, 4),\n",
        "            nn.Sigmoid())\n",
        "        self.apply(weights_init)        \n",
        "    def forward(self, x):\n",
        "        y = self.ls(x)\n",
        "        y = y.view(-1)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vJvOcDx23Iy"
      },
      "source": [
        "Training\n",
        "设定好 hyperparameters。 准备 dataloader, model, loss criterion, optimizer。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2-5ic2Y26Fl"
      },
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "\n",
        "# hyperparameters \n",
        "batch_size = 8\n",
        "z_dim = 100\n",
        "lr = 1e-4\n",
        "n_epoch = 10\n",
        "save_dir = os.path.join(workspace_dir, 'logs')\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# model\n",
        "G = Generator(in_dim=z_dim).cuda()\n",
        "D = Discriminator(3).cuda()\n",
        "G.train()\n",
        "D.train()\n",
        "\n",
        "# loss criterion\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# optimizer\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "\n",
        "same_seeds(0)\n",
        "# dataloader (You might need to edit the dataset path if you use extra dataset.)\n",
        "#dataset = get_dataset(os.path.join(workspace_dir, 'faces'))\n",
        "dataset = get_dataset(os.path.join(workspace_dir, 'MNIST_GAN_1000'))\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAfNR-i12-UC"
      },
      "source": [
        "# 输出一个数据集中的训练样本\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(dataset[10].numpy().transpose(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We0jL9SU3AuE"
      },
      "source": [
        "# for logging\n",
        "z_sample = Variable(torch.randn(100, z_dim)).cuda()\n",
        "\n",
        "for e, epoch in enumerate(range(n_epoch)):\n",
        "    for i, data in enumerate(dataloader):\n",
        "        imgs = data\n",
        "        imgs = imgs.cuda()\n",
        "\n",
        "        bs = imgs.size(0)\n",
        "\n",
        "        \"\"\" Train D \"\"\"\n",
        "        z = Variable(torch.randn(bs, z_dim)).cuda()\n",
        "        r_imgs = Variable(imgs).cuda()\n",
        "        f_imgs = G(z)\n",
        "\n",
        "        # label        \n",
        "        r_label = torch.ones((bs)).cuda()\n",
        "        f_label = torch.zeros((bs)).cuda()\n",
        "\n",
        "        # dis\n",
        "        r_logit = D(r_imgs.detach())\n",
        "        f_logit = D(f_imgs.detach())\n",
        "        \n",
        "        # compute loss\n",
        "        r_loss = criterion(r_logit, r_label)\n",
        "        f_loss = criterion(f_logit, f_label)\n",
        "        loss_D = (r_loss + f_loss) / 2\n",
        "\n",
        "        # update model\n",
        "        D.zero_grad()\n",
        "        loss_D.backward()\n",
        "        opt_D.step()\n",
        "\n",
        "        \"\"\" train G \"\"\"\n",
        "        # leaf\n",
        "        z = Variable(torch.randn(bs, z_dim)).cuda()\n",
        "        f_imgs = G(z)\n",
        "\n",
        "        # dis\n",
        "        f_logit = D(f_imgs)\n",
        "        \n",
        "        # compute loss\n",
        "        loss_G = criterion(f_logit, r_label)\n",
        "\n",
        "        # update model\n",
        "        G.zero_grad()\n",
        "        loss_G.backward()\n",
        "        opt_G.step()\n",
        "\n",
        "        # log\n",
        "        print(f'\\rEpoch [{epoch+1}/{n_epoch}] {i+1}/{len(dataloader)} Loss_D: {loss_D.item():.4f} Loss_G: {loss_G.item():.4f}', end='')\n",
        "    G.eval()\n",
        "    f_imgs_sample = (G(z_sample).data + 1) / 2.0\n",
        "    filename = os.path.join(save_dir, f'Epoch_{epoch+1:03d}.jpg')\n",
        "    torchvision.utils.save_image(f_imgs_sample, filename, nrow=10)\n",
        "    print(f' | Save some samples to {filename}.')\n",
        "    # show generated image\n",
        "    grid_img = torchvision.utils.make_grid(f_imgs_sample.cpu(), nrow=10)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(grid_img.permute(1, 2, 0))\n",
        "    plt.show()\n",
        "    G.train()\n",
        "    if (e+1) % 5 == 0:\n",
        "        torch.save(G.state_dict(), os.path.join(workspace_dir, f'dcgan_g.pth'))\n",
        "        torch.save(D.state_dict(), os.path.join(workspace_dir, f'dcgan_d.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogCmqMNK3C5p"
      },
      "source": [
        "\n",
        "Inference\n",
        "利用训练好的 Generator 随机生成图片。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvoIJSQT3DTf"
      },
      "source": [
        "import torch\n",
        "# load pretrained model\n",
        "G = Generator(z_dim)\n",
        "G.load_state_dict(torch.load(os.path.join(workspace_dir, 'dcgan_g.pth')))\n",
        "G.eval()\n",
        "G.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YygyZSyK3GhA"
      },
      "source": [
        "# generate images and save the result\n",
        "n_output = 20\n",
        "z_sample = Variable(torch.randn(n_output, z_dim)).cuda()\n",
        "imgs_sample = (G(z_sample).data + 1) / 2.0\n",
        "save_dir = os.path.join(workspace_dir, 'logs')\n",
        "filename = os.path.join(save_dir, f'result.jpg')\n",
        "torchvision.utils.save_image(imgs_sample, filename, nrow=10)\n",
        "# show image\n",
        "grid_img = torchvision.utils.make_grid(imgs_sample.cpu(), nrow=10)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}